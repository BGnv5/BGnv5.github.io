{"pages":[],"posts":[{"title":"Hello World","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new \"My New Post\" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","link":"/2020/03/20/hello-world/"},{"title":"test","text":"模板 title: 使用Hexo搭建个人博客 layout: post date: 2014-03-03 19:07:43 comments: true categories: Blog tags: [Hexo] keywords: Hexo, Blog description: 生命在于折腾，又把博客折腾到Hexo了。给Hexo点赞。","link":"/2020/03/24/test/"},{"title":"LeetCode 148.Sort List","text":"sort-list题目描述：在O(n log n)的时间内使用常数级空间复杂度对链表进行排序。Sort a linked list in O(n log n) time using constant space complexity. 思路分析：1. 归并排序（递归法）： 如果链表为空，或者只有一个结点则直接返回这个链表 不为空，利用快慢指针把链表为成左右两部分，当快指针所指向结点不为空并且存在下一个元素时，快指针走两步，慢指针走一步。 慢指针所指向的下一个结点即为右半部分的开始，并把slow指向的下一个结点置为空。 依次递归直到左右两半部分只含有一个结点为止。 最后在进行归并。 时间复杂度：O(n log n)空间复杂度：O(n) 2. 归并排序（迭代法）： 定义一个头结点，让这个头结点的next指向head 统计链表中一共有几个结点，并遍历整个链表 每次截取长度为size的链表进行归并，每轮过后size长度*2，直到size长度等于链表的长度，设size初始值为1。 最后返回头结点指向的下一个结点 时间复杂度：O(n log n)空间复杂度：O(1) 算法实现：1.归并排序（递归法）： 123456789101112131415161718192021222324252627282930313233public class Solution { public ListNode sortList(ListNode head) { if(head == null || head.next == null) return head; ListNode slow = head; ListNode fast = head.next; while(fast != null &amp;&amp; fast.next != null){ slow = slow.next; fast = fast.next.next; } ListNode mid = slow.next; slow.next = null; ListNode left = sortList(head); ListNode right = sortList(mid); ListNode temp = new ListNode(0); ListNode p = temp; while(left != null &amp;&amp; right != null){ if(left.val &lt; right.val){ p.next = left; left = left.next; }else{ p.next = right; right = right.next; } p = p.next; } if(left != null) { p.next = left; }else{ p.next = right; } return temp.next; }} 2. 归并排序（迭代法） 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960public class Solution { public ListNode sortList(ListNode head) { //求链表长度 ListNode p = head; int len = 0; while(p != null){ len ++; p = p.next; } ListNode pHead = new ListNode(0); pHead.next = head;//主要是考虑到只有一个结点的情况 for(int size = 1; size &lt; len; size *= 2){ ListNode cur = pHead.next;//一轮结束cur要回到链表首部 ListNode next = pHead;//一轮结束next回到初始位置 while(cur != null){ ListNode left = cur; ListNode right = cut(left,size); cur = cut(right,size); next.next = merge(left,right); while(next.next != null){ next = next.next; } } } return pHead.next; } //根据步长分割链表 private ListNode cut(ListNode head, int size){ if(head == null) return head; for (int i = 1; head.next != null &amp;&amp; i &lt; size; i++) { head = head.next; } ListNode nextHead = head.next; head.next = null; return nextHead; } //归并链表 private ListNode merge(ListNode left, ListNode right){ ListNode head = new ListNode(0); ListNode p = head; while(left != null &amp;&amp; right != null){ if(left.val &lt; right.val){ p.next = left; left = left.next; }else{ p.next = right; right = right.next; } p = p.next; } if(left != null) p.next = left; else p.next = right; return head.next; }}","link":"/2020/03/25/LeetCode-148-Sort-List/"},{"title":"LeetCode 147.insert-sort-list","text":"insert-sort-list题目描述：使用插入排序对链表进行排序。Sort a linked list using insertion sort. 思路分析： 如果链表为空,返回null 链表非空，定义一个头结点，遍历整个链表 定义一个变量pre用来指示应该插入的位置，如果这个变量所在位置的值小于待插入元素的值，并且这个变量存在下一个结点，则变量的位置后移一位，最终所在位置即为待插入的位置。 用一个变量cur来指示待插入数所在位置，并修改待插入数所指向下一个结点的位置,让它等于pre.next 修改带插入位置的下一个结点,让它等于cur 算法实现：123456789101112131415161718public class Solution { public ListNode insertionSortList(ListNode head) { if(head == null) return null; ListNode pHead = new ListNode(0); ListNode cur = head; while(cur != null){ ListNode pre = pHead; ListNode next = cur.next; while(pre.next != null &amp;&amp; pre.next.val &lt; cur.val){ pre = pre.next; } cur.next = pre.next; pre.next = cur; cur = next; } return pHead.next; }}","link":"/2020/03/25/LeetCode-147-insert-sort-list/"},{"title":"史上最详细的hive安装教程，避免踩坑系列","text":"网上安装教程很多，照着安装还会出现各种各样的错误，这篇文章手把手教你安装hive，对安装时常见的几种错误也进行了汇总，让你能够轻松避免踩坑~ Hive 安装部署derby版 Hive前提：安装配置好 Jdk 和 hadoop,并启动 hdfs。 下载安装包,并上传到/opt/software下 地址：[https://mirrors.tuna.tsinghua.edu.cn/apache/hive/] 解压hive压缩包到/opt/module下： 1tar -zxvf apache-hive-1.2.1-bin.tar.gz -C ../module 将文件重命名为hive-1.2.1文件： 1mv apache-hive-1.2.1-bin/ hive-1.2.1 进入bin目录直接启动 12[root@hadoop100 software]# cd ../module/hive-1.2.1/[root@hadoop100 hive-1.2.1]# bin/hive 测试一下，查看数据库，出现如下所示即安装成功！ 1234hive&gt; show databases;OKdefaultTime taken: 1.63 seconds, Fetched: 1 row(s) 注意： 如果启动hive时如果报: 1Call From hadoop /192.168.1.100 to hadoop :9000 failed on connection 解决方案： 进入hadoop/bin目录下，格式化namenode 12[root@hadoop100 module]# cd hadoop-2.7.1/bin[root@hadoop100 bin]# hadoop namenode -format 然后进入hadoop/sbin 执行 sh stop-all.sh 12[root@hadoop100 bin]# cd ../sbin[root@hadoop100 sbin]# sh stop-all.sh 最后重新启动 sh start-all.sh即可 1[root@hadoop100 sbin]# sh start-all.sh 缺点：使用内置 derby版，不同路径启动hive，每个hive拥有一套自己的元数据，无法共享。 Mysql版 Hive安装并配置MySQL 查看是否安装MySql1rpm -qa|grep -i mysql 如果已经安装过,卸载安装过MySQL:1rpm -ev --nodeps mysql-libs-5.1.71-1.el6.x86_64 删除其他配置12rm -rf /usr/my.cnfrm -rf /root/.mysql_sercret 下载并安装MySQL官方的 Yum Repository 1wget -i -c http://dev.mysql.com/get/mysql57-community-release-el7-10.noarch.rpm 使用 yum 进行安装 1yum -y install mysql57-community-release-el7-10.noarch.rpm 安装MySQL（完成后就会覆盖掉之前的mariadb） 1yum -y install mysql-server mysql 启动MySql服务 1[root@hadoop100 ~]# systemctl start mysqld.service 启动mysql时报错： 1Job for mysqld.service failed because the control process exited with error code. See \"systemctl status mysqld.service\" and \"journalctl -xe\" for details. 解决方法： 修改/var/lib/mysql 文件的权限1[root@hadoop100 ~]# chmod -R 777 /var/lib/mysql 删除/var/lib/mysql 下的所有文件1[root@hadoop100 ~]# rm -rf /var/lib/mysql/* 重新启动mysql服务1[root@hadoop100 ~]# systemctl start mysqld.service 查看MySQL运行状态,出现下图所示即启动成功1[root@hadoop100 ~]# systemctl status mysqld.service 12345678910111213● mysqld.service - MySQL Server Loaded: loaded (/usr/lib/systemd/system/mysqld.service; enabled; vendor preset: disabled) Active: active (running) since 二 2020-03-31 10:29:00 CST; 24s ago Docs: man:mysqld(8) http://dev.mysql.com/doc/refman/en/using-systemd.html Process: 4054 ExecStart=/usr/sbin/mysqld --daemonize --pid-file=/var/run/mysqld/mysqld.pid $MYSQLD_OPTS (code=exited, status=0/SUCCESS) Process: 4005 ExecStartPre=/usr/bin/mysqld_pre_systemd (code=exited, status=0/SUCCESS) Main PID: 4057 (mysqld) CGroup: /system.slice/mysqld.service └─4057 /usr/sbin/mysqld --daemonize --pid-file=/var/run/mysqld/mysqld.pid3月 31 10:28:51 hadoop100 systemd[1]: Starting MySQL Server...3月 31 10:29:00 hadoop100 systemd[1]: Started MySQL Server. 登入MySQL1[root@hadoop100 ~]# mysql -u root -p 连接MySQL报错： 1ERROR 1045 (28000): Access denied for user 'root'@'localhost' (using password: NO) 解决方法： 查看root用户的密码1[root@hadoop100 ~]# grep \"password\" /var/log/mysqld.log 12345678910111213141516171819202122232425262728293031323334353637382020-03-30T17:20:05.867355Z 1 [Note] A temporary password is generated for root@localhost: Qsye(dZPq2020-03-30T17:30:01.493042Z 2 [Note] Access denied for user 'root'@'localhost' (using password: YES)2020-03-30T17:30:43.027818Z 3 [Note] Access denied for user 'root'@'localhost' (using password: YES)2020-03-30T17:30:58.234454Z 4 [Note] Access denied for user 'root'@'localhost' (using password: YES)2020-03-30T17:31:29.410990Z 5 [Note] Access denied for user 'root'@'localhost' (using password: YES)2020-03-30T17:31:43.170470Z 6 [Note] Access denied for user 'root'@'localhost' (using password: YES)2020-03-30T17:33:41.321386Z 8 [Note] Access denied for user 'root'@'localhost' (using password: YES)2020-03-30T17:50:55.265575Z 11 [Note] Access denied for user 'root'@'localhost' (using password: YES2020-03-30T19:27:01.508362Z 0 [Note] Shutting down plugin 'validate_password'2020-03-30T19:27:04.113128Z 0 [Note] Shutting down plugin 'sha256_password'2020-03-30T19:27:04.113136Z 0 [Note] Shutting down plugin 'mysql_native_password'2020-03-31 04:30:50 3851 [Note] Shutting down plugin 'sha256_password'2020-03-31 04:30:50 3851 [Note] Shutting down plugin 'mysql_old_password'2020-03-31 04:30:50 3851 [Note] Shutting down plugin 'mysql_native_password'2020-03-31 04:45:55 6906 [Note] Shutting down plugin 'sha256_password'2020-03-31 04:45:55 6906 [Note] Shutting down plugin 'mysql_old_password'2020-03-31 04:45:55 6906 [Note] Shutting down plugin 'mysql_native_password'2020-03-31 04:55:55 8956 [Note] Shutting down plugin 'sha256_password'2020-03-31 04:55:55 8956 [Note] Shutting down plugin 'mysql_old_password'2020-03-31 04:55:55 8956 [Note] Shutting down plugin 'mysql_native_password'2020-03-31 05:06:10 11074 [Note] Shutting down plugin 'sha256_password'2020-03-31 05:06:10 11074 [Note] Shutting down plugin 'mysql_old_password'2020-03-31 05:06:10 11074 [Note] Shutting down plugin 'mysql_native_password'2020-03-31 05:15:11 13422 [Note] Shutting down plugin 'sha256_password'2020-03-31 05:15:11 13422 [Note] Shutting down plugin 'mysql_old_password'2020-03-31 05:15:11 13422 [Note] Shutting down plugin 'mysql_native_password'2020-03-31 05:25:12 15960 [Note] Shutting down plugin 'sha256_password'2020-03-31 05:25:12 15960 [Note] Shutting down plugin 'mysql_old_password'2020-03-31 05:25:12 15960 [Note] Shutting down plugin 'mysql_native_password'2020-03-31 09:39:35 2385 [Note] Shutting down plugin 'sha256_password'2020-03-31 09:39:35 2385 [Note] Shutting down plugin 'mysql_old_password'2020-03-31 09:39:35 2385 [Note] Shutting down plugin 'mysql_native_password'2020-03-31T02:28:54.650273Z 1 [Note] A temporary password is generated for root@localhost: lts2L)L&lt;h2020-03-31T02:30:15.184424Z 2 [Note] Access denied for user 'root'@'localhost' (using password: NO)2020-03-31T02:30:24.888102Z 3 [Note] Access denied for user 'root'@'localhost' (using password: NO)2020-03-31T02:30:44.372240Z 4 [Note] Access denied for user 'root'@'localhost' (using password: YES)2020-03-31T02:34:40.134792Z 5 [Note] Access denied for user 'root'@'localhost' (using password: YES)2020-03-31T02:34:49.375071Z 6 [Note] Access denied for user 'root'@'localhost' (using password: YES) 根据查找到的密码重新登入即可12345[root@hadoop100 ~]# mysql -uroot -pEnter password: Welcome to the MySQL monitor. Commands end with ; or \\g.Your MySQL connection id is 12Server version: 5.7.29 修改密码（这里用户名为root，密码为BGnv5_Oooh）1mysql&gt; ALTER USER 'root'@'localhost' IDENTIFIED BY 'BGnv5_Oooh'; 注意: 密码设置必须要大小写字母数字和特殊符号（,/‘;:等）,不然不能配置成功 使用mysql数据库 1mysql&gt; use mysql; 把在所有数据库的所有表的所有权限赋值给位于所有IP地址的root用户 1mysql&gt; update user set host = '%' where user = 'root'; 配置远程连接 1mysql&gt; grant all privileges on *.* to root@'%'identified by 'BGnv5_Oooh' with grant option; 刷新MySQL的系统权限相关表 12mysql&gt; flush privileges;mysql&gt; exit; 安装并配置hive 下载hive压缩包并解压到/opt/module下： 1tar -zxvf apache-hive-1.2.1-bin.tar.gz -C ../module 配置HIVE环境变量 1234567[root@hadoop100 ~]vim /etc/profile##Hiveexport HIVE_HOME=/opt/module/hive-1.2.1export PATH=$PATH:$HIVE_HOME/bin[root@hadoop100 ~]# source /etc/profile 进入hive/conf 目录下1[root@hadoop100 ~]# cd /opt/module/hive-1.2.1/conf/ 配置hive-env.sh文件 12345678[root@hadoop100 conf]# cp hive-env.sh.template hive-env.sh[root@hadoop100 conf]# vim hive-env.sh# Set HADOOP_HOME to point to a specific hadoop install directoryexport HADOOP_HOME=/opt/module/hadoop-2.7.1# Hive Configuration Directory can be controlled by:export HIVE_CONF_DIR=/opt/module/hive-1.2.1/conf 配置 hive-site.xml文件(默认不存在) 12345678910111213141516171819202122[root@hadoop100 conf]# vim hive-site.xml&lt;?xml-stylesheet type=\"text/xsl\" href=\"configuration.xsl\"?&gt;&lt;configuration&gt; &lt;property&gt; &lt;name&gt;javax.jdo.option.ConnectionURL&lt;/name&gt; &lt;value&gt;jdbc:mysql://localhost/metastore?createDatabaseIfNotExist=true&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;javax.jdo.option.ConnectionDriverName&lt;/name&gt; &lt;value&gt;com.mysql.jdbc.Driver&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;javax.jdo.option.ConnectionUserName&lt;/name&gt; &lt;value&gt;root&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;javax.jdo.option.ConnectionPassword&lt;/name&gt; &lt;value&gt;BGnv5_Oooh&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; 将驱动包mysql-connector-java-5.1.38.jar 放在hive/lib目录下 1[root@hadoop100 conf]# cd /opt/module/hive-1.2.1/lib 对MySQL 进行初始化 1[root@hadoop100 conf]# schematool -dbType mysql -initSchema 启动hadoop集群 12[root@hadoop100 conf]# cd /opt/module/hadoop-2.7.1/[root@hadoop100 hadoop-2.7.1]# sbin/start-all.sh 启动Hve 1[root@hadoop100 conf]# hive 测试hive 在hive/conf目录下创建一个BGnv5数据库，并查看数据库123hive&gt; create database BGnv5;OKTime taken: 1.317 seconds 12345hive&gt; show databases;OKbgnv5defaultTime taken: 0.664 seconds, Fetched: 2 row(s) 切换到主目录,在主目录处启动hive，并查看数据库 1[root@hadoop100 conf]# cd 1[root@hadoop100 ~]# hive 12345hive&gt; show databases;OKbgnv5defaultTime taken: 1.565 seconds, Fetched: 2 row(s) 可以观察到不论是在哪里启动hive，数据都可以共享，MySQL版hive安装成功。","link":"/2020/03/31/%E5%8F%B2%E4%B8%8A%E6%9C%80%E8%AF%A6%E7%BB%86%E7%9A%84hive%E5%AE%89%E8%A3%85%E6%95%99%E7%A8%8B%EF%BC%8C%E9%81%BF%E5%85%8D%E8%B8%A9%E5%9D%91%E7%B3%BB%E5%88%97/"},{"title":"Hive基本介绍","text":"什么是Hive？我们为什么使用它？它有哪些优缺点？它与传统的关系型数据库相比有何不同？它的架构原理是怎样的？ Hive 简介什么是Hive?&emsp;&emsp;hive是由 Facebook 实现并开源的一个基于Hadoop的数据仓库工具，它的底层数据是存储在HDFS上的，它提供了类似SQL的 Hive SQL语言，能够将结构化的数据映射为一张数据库表，其底层原理是将HQL 语言转化为MapReduce 任务执行，从而完成对Hadoop集群中存储的海量数据进行查询和分析。 为什么使用Hive?&emsp;&emsp;hive提供了类SQL的语法，避免了写实现复杂逻辑的MapReduce程序，从而降低了开发人员的学习成本，提高开发人员快速开发的能力，并且hive还具有更好的扩展性，可以自由扩展集群规模而无需重启服务，还支持用户自定义函数。 Hive的优缺点优点： 简单易上手：提供了类SQL查询语言HQL 可扩展：Hive可以自由的扩展集群的规模，一般情况下不需要重启服务就可以进行扩展 提供了同一的元数据管理 延展性：Hive支持自定义函数，用户可以根据自己的需求来实现自己的函数 容错性：良好的容错性，结点出现故障，SQL语句仍可以完成执行 缺点： Hive延时严重：启动MapReduce Job时有延迟 Hive不支持记录级别的增删改操作，但是用户可以通过查询生成新表或者将查询结果导入到文件中 Hive不支持事务：主要用来做OLAP(联机分析处理)，而不适用OLTP（联机事务处理） Hive 与RDBMS 的对比 Hive使用HDFS存储数据，而关系型数据库则是存储在服务器本地的文件系统中； Hive使用MapReduce作为计算模型，而关系型数据库则是使用自己设计的计算模型 Hive实时性差它是为海量数据做数据挖掘设计的；而关系型数据库实时性好，它是为实时查询的业务进行设计的 Hive扩展性强，可以很容易的扩展自己的存储能力和计算能力，而关系型数据库在这方面相对较差 Hive不支持对某个具体行的操作，对数据的操作只支持覆盖原数据和追加数据；而关系型数据库支持对行级的更新删除 Hive是”读时模式”，即在加载数据的时候不会对数据进行检查/更改，在查询操作时才会检查数据的格式；而关系型数据库是”写时模式”，在数据加载的时候就会对数据模式进行检查校验的操作。 Hive延迟较高，因为Hive不支持索引，所以查询的时候会扫描整个表，而且Hive在启动MapReduce Job的时候也会造成较大的延迟；而关系型数据库支持复杂索引，所以延迟相对较小 Hive 架构 Hive架构设计Hive架构设计主要包括三个部分： Hive Clients：Hive客户端，它为不同类型的应用程序提供不同的驱动，使得Hive可以通过类似Java、Python等语言连接，同时也提供了JDBC和ODBC驱动。 Hive Services：Hive服务端，客户端必须通过服务端与Hive交互，主要包括：&emsp;&emsp;用户接口组件（CLI，HiveServer，HWI），它们分别以命令行、与web的形式连接Hive。&emsp;&emsp;Driver组件，该组件包含编译器、优化器和执行引擎，它的作用是将hiveSQL语句进行解析、编译优化、生成执行计划，然后调用底层MR计算框架。&emsp;&emsp;Metastore组件，元数据服务组件。Hive数据分为两个部分，一部分真实数据保存在HDFS中，另一部分是真实数据的元数据，一般保存在MySQL中，元数据保存了真实数据的很多信息，是对真实数据的描述。 Hive Storage and Computing:包括元数据存储数据库和Hadoop集群。Hive元数据存储在RDBMS中，Hive数据存储在HDFS中，查询由MR完成。 Hive各组件说明 thrift server：跨语言服务提供了一种能力，让用户可以使用多种不同的语言来操纵hive 用户接口: shell/CLI, jdbc/odbc, webui Command Line Interface CLI，Shell 终端命令行（Command Line Interface），采用交互形式使用 Hive 命令行与 Hive 进行交互，最常用（学习，调试，生产） JDBC/ODBC，是Hive基于JDBC操作提供的客户端，用户（开发员，运维人员）通过这连接至 Hive server 服务 Web UI，通过浏览器访问 Hive 驱动器Driver：它是Hive的核心,主要完成HQL查询语句从词法分析，语法分析，编译，优化，以及逻辑执行计划的生成。生成的逻辑执行计划存储在HDFS中，并随后由MapReduce调用执行。 &emsp;&emsp;Driver驱动引擎由四部分组成： &emsp;&emsp;&emsp;&emsp;解释器：解释器的作用是将HiveSQL语句转换为抽象语法树（AST）&emsp;&emsp;&emsp;&emsp;编译器Compiler：编译器是将语法树编译为逻辑执行计划&emsp;&emsp;&emsp;&emsp;优化器Optimizer：优化器是对逻辑执行计划进行优化&emsp;&emsp;&emsp;&emsp;执行器Executor：执行器是调用底层的运行框架执行逻辑执行计划 元数据存储系统RDBMS MySQL：存储在 Hive 中的数据的描述信息 Hive 中的元数据通常包括：表的名字，表的列和分区及其属性，表的属性（内部表和外部表），表的数据所在目录等 Metastore 默认存在自带的Derby数据库中。缺点就是不适合多用户操作，数据存储目录不固定。数据库跟着Hive走，极度不方便管理。因此建议存储在关系型数据库中 Hive 具体工作流程 1）用户通过用户接口提交查询任务给Driver。 2）Driver获得该用户的计划，调用编译器检查查询语法并分析查询计划和要求。 3）编译器Compiler根据用户任务到MetaStore中请求需要的Hive的元数据信息。 4）Metastore发送元数据信息给编译器 5）编译器对任务进行编译，先将HiveQL转换为抽象语法树，然后将抽象语法树转换成查询块，将查询块转化为逻辑的查询计划，重写逻辑查询计划，将逻辑计划转化为物理的计划（MapReduce）,最后选择最佳的策略。并将计划提交给Driver。 6）Driver将计划转交给执行引擎ExecutionEngine去执行 7）执行引擎发送作业给JobTracker，执行引擎获取元数据信息（这是在名称节点），并把它分配作业到TaskTracker（这是在数据节点），在这里查询执行MapReduce工作。与此同时，在执行时，执行引擎可以通过Metastore执行元数据操作（虚线部分）。 8）执行引擎接收来自数据节点的执行结果。 9）执行引擎发送这些结果给驱动程序。 10）驱动程序将结果发送给Hive接口（返回给用户）","link":"/2020/04/02/Hive%E5%9F%BA%E6%9C%AC%E4%BB%8B%E7%BB%8D/"}],"tags":[{"name":"test","slug":"test","link":"/tags/test/"},{"name":"LeetCode","slug":"LeetCode","link":"/tags/LeetCode/"},{"name":"hive","slug":"hive","link":"/tags/hive/"}],"categories":[{"name":"test","slug":"test","link":"/categories/test/"},{"name":"LeetCode","slug":"LeetCode","link":"/categories/LeetCode/"},{"name":"hive","slug":"hive","link":"/categories/hive/"}]}